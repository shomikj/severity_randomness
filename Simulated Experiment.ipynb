{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bdc9dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de638e3e",
   "metadata": {},
   "source": [
    "Simulated Experiment:\n",
    "- Generate 1000 risk scores ~ Uniform(0,1)\n",
    "- Simulate true outcome = Bernoulli(risk) \n",
    "- Threshold prediction = 1 if risk >= 0.5, 0 else\n",
    "- Random prediction = Bernoulli(risk) \n",
    "\n",
    "If multiple decision-makers (models) estimate the same risk, does homogenization improve with random predictions? \n",
    "- Each model flips its own Bernoulli coin instead of using the same threshold\n",
    "- Overall experiment conducted 1000 times  \n",
    "\n",
    "Partially Random Classifier:\n",
    "- Use random prediction if risk between some upper and lower bound (e.g. 0.4 to 0.6)\n",
    "- Otherwise use threshold prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aef07a",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6d43ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracker:\n",
    "    def __init__(self, random_distance, num_models, size=1000):\n",
    "        self.random_distance = random_distance\n",
    "        self.num_models = num_models\n",
    "        \n",
    "        self.accuracy = []\n",
    "        self.acceptance = []\n",
    "        \n",
    "        self.systemic_success = (np.ones(size)==1)\n",
    "        self.systemic_failure = (np.ones(size)==1)\n",
    "        \n",
    "        self.failure_rate = 1\n",
    "    \n",
    "    def get_predictions(self, risk, random_pred, threshold_pred):\n",
    "        pred = []\n",
    "        for i in range(len(risk)):\n",
    "            if (risk[i]>0.5-self.random_distance) and (risk[i]<0.5+self.random_distance):\n",
    "                pred.append(random_pred[i])\n",
    "            else:\n",
    "                pred.append(threshold_pred[i])\n",
    "        return np.array(pred)\n",
    "    \n",
    "    def update_metrics(self, risk, random_pred, threshold_pred, outcomes):\n",
    "        pred = self.get_predictions(risk, random_pred, threshold_pred)\n",
    "        \n",
    "        self.accuracy.append(np.sum(pred==outcomes)/len(pred))\n",
    "        self.acceptance.append(np.sum(pred)/len(pred))\n",
    "\n",
    "        self.failure_rate *= np.sum(pred==0)/len(pred)\n",
    "        \n",
    "        self.systemic_success *= (pred==1)\n",
    "        self.systemic_failure *= (pred==0)\n",
    "\n",
    "    def final_metrics(self):\n",
    "        r = {}\n",
    "        r[\"random_distance\"] = self.random_distance\n",
    "        r[\"num_models\"] = self.num_models\n",
    "        \n",
    "        r[\"accuracy\"] = np.mean(self.accuracy)\n",
    "        r[\"acceptance\"] = np.mean(self.acceptance)\n",
    "        \n",
    "        r[\"systemic_success\"] = np.sum(self.systemic_success)/len(self.systemic_success)\n",
    "        r[\"systemic_failure\"] = np.sum(self.systemic_failure)/len(self.systemic_failure)\n",
    "        r[\"multiplicity\"] = 1-r[\"systemic_success\"]-r[\"systemic_failure\"]\n",
    "        \n",
    "        r[\"failure_rate\"] = self.failure_rate\n",
    "        r[\"homogenization_expected_failure\"] = r[\"systemic_failure\"]/self.failure_rate\n",
    "        r[\"homogenization_avg_failure\"] = r[\"systemic_failure\"]/(1-r[\"acceptance\"])\n",
    "        \n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5204642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(num_models=2):\n",
    "    results = []\n",
    "    \n",
    "    for i in range(1000):\n",
    "        risk = np.random.uniform(0,1,1000)\n",
    "        \n",
    "        outcomes = []\n",
    "        for r in risk:\n",
    "            outcomes.append(np.random.binomial(1, r))\n",
    "        \n",
    "        threshold = Tracker(0, num_models)\n",
    "        random_10 = Tracker(0.1, num_models)\n",
    "        random_20 = Tracker(0.2, num_models)\n",
    "        random_30 = Tracker(0.3, num_models)\n",
    "        random_40 = Tracker(0.4, num_models)\n",
    "        random = Tracker(0.5, num_models)\n",
    "        \n",
    "        for k in range(num_models):\n",
    "            random_pred = []\n",
    "            threshold_pred = []\n",
    "\n",
    "            for r in risk:\n",
    "                random_pred.append(np.random.binomial(1, r))\n",
    "                if r>=0.5:\n",
    "                    threshold_pred.append(1)\n",
    "                else:\n",
    "                    threshold_pred.append(0)\n",
    "            \n",
    "            threshold.update_metrics(risk, random_pred, threshold_pred, outcomes)\n",
    "            random_10.update_metrics(risk, random_pred, threshold_pred, outcomes)\n",
    "            random_20.update_metrics(risk, random_pred, threshold_pred, outcomes)\n",
    "            random_30.update_metrics(risk, random_pred, threshold_pred, outcomes)\n",
    "            random_40.update_metrics(risk, random_pred, threshold_pred, outcomes)\n",
    "            random.update_metrics(risk, random_pred, threshold_pred, outcomes)\n",
    "        \n",
    "        results.append(threshold.final_metrics())\n",
    "        results.append(random_10.final_metrics())\n",
    "        results.append(random_20.final_metrics())\n",
    "        results.append(random_30.final_metrics())\n",
    "        results.append(random_40.final_metrics())\n",
    "        results.append(random.final_metrics())\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20c9fda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for k in tqdm(range(1, 11)):\n",
    "    results += experiment(k)\n",
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d82127a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby([\"random_distance\", \"num_models\"]).mean().reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e202282",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3318e0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df, title, metric, ylog=False):\n",
    "    plt.rcParams[\"figure.figsize\"] = [7,3]\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    plt.plot(df.loc[df[\"random_distance\"]==0, \"num_models\"], df.loc[df[\"random_distance\"]==0, metric], '*-', color='#00060e', label=\"Threshold\")\n",
    "    plt.plot(df.loc[df[\"random_distance\"]==0.1, \"num_models\"], df.loc[df[\"random_distance\"]==0.1, metric], '*-', color='#001e49', label=\"Random(0.4,0.6)\")\n",
    "    plt.plot(df.loc[df[\"random_distance\"]==0.2, \"num_models\"], df.loc[df[\"random_distance\"]==0.2, metric], '*-', color='#002f70', label=\"Random(0.3,0.7)\")\n",
    "    plt.plot(df.loc[df[\"random_distance\"]==0.3, \"num_models\"], df.loc[df[\"random_distance\"]==0.3, metric], '*-', color='#003f97', label=\"Random(0.2,0.8)\")\n",
    "    plt.plot(df.loc[df[\"random_distance\"]==0.4, \"num_models\"], df.loc[df[\"random_distance\"]==0.4, metric], '*-', color='#004fbf', label=\"Random(0.1,0.9)\")\n",
    "    plt.plot(df.loc[df[\"random_distance\"]==0.5, \"num_models\"], df.loc[df[\"random_distance\"]==0.5, metric], '*-', color='#0068f9', label=\"All Random\")\n",
    "  \n",
    "    #plt.ylim(0,1)\n",
    "    if ylog:\n",
    "        plt.yscale('log')   \n",
    "\n",
    "    plt.xlabel('Number of models')\n",
    "    plt.ylabel(metric)\n",
    "    plt.title(title)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bad77ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(df, \"Accuracy\", \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4e8d6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(df, \"Systemic Failure\", \"systemic_failure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdbedbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(df, \"Systemic Success\", \"systemic_success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d048acc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(df, \"Multiplicity\", \"multiplicity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bdd765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(df, \"Acceptance Rate\", \"acceptance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20675c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(df, \"Homogenization (Systemic Failure / Expected Failure)\", \"homogenization_expected_failure\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d7468d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(df, \"Homogenization (Systemic Failure / Expected Failure)\", \"homogenization_expected_failure\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c2bc9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(df, \"Expected Failure Rate\", \"failure_rate\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fe7cb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(df, \"Homogenization (Systemic Failure / Average Failure)\", \"homogenization_avg_failure\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
