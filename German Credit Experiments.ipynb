{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3be97283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm, ensemble\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bfa6b2",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "baad157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRAIN = 800\n",
    "N_TEST = 200\n",
    "german_credit = pd.read_csv('data/german_credit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a79e979",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "'status_checking_account',\n",
    "'duration_in_month',\n",
    "'credit_history',\n",
    "'purpose',\n",
    "'savings',\n",
    "'employement_since',\n",
    "'installment_rate',\n",
    "'debters',\n",
    "'resident_since',\n",
    "'property',\n",
    "'age',\n",
    "'other_installments',\n",
    "'housing',\n",
    "'num_credits',\n",
    "'job',\n",
    "'num_liable',\n",
    "'telephone',\n",
    "'foreign_worker'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2992795b",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "099ca5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(df, application_name, seed, attribute_name=\"gender\"):\n",
    "    df_train, df_test = sklearn.model_selection.train_test_split(df, test_size=0.2, random_state=seed)\n",
    "\n",
    "    X_train, X_test = df_train[features].to_numpy(), df_test[features].to_numpy()\n",
    "    y_train, y_test = df_train[application_name].to_numpy(), df_test[application_name].to_numpy()\n",
    "    z_train, z_test = df_train[attribute_name].to_numpy(), df_test[attribute_name].to_numpy()\n",
    "    \n",
    "    return {'X_tr' : X_train, 'X_test' : X_test, 'y_tr': y_train, 'y_test' : y_test, 'z_tr': z_train, 'z_test': z_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c707679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_partition(data, seed, data_scale):\n",
    "    rng = random.Random(seed)\n",
    "    index = rng.randint(0, int(data_scale) - 1)\n",
    "\n",
    "    X_train, y_train, z_train = data['X_tr'], data['y_tr'], data['z_tr']\n",
    "    X_test, y_test, z_test = data['X_test'], data['y_test'], data['z_test']\n",
    "    y_train = np.expand_dims(y_train, axis = 1)\n",
    "    z_train = np.expand_dims(z_train, axis = 1)\n",
    "    data = np.concatenate((X_train, y_train, z_train), axis = 1)\n",
    "    np.random.RandomState(seed=seed).shuffle(data)\n",
    "    X_train, y_train, z_train = data[:, : -2], data[:, -2], data[:, -1]\n",
    "\n",
    "    N = len(y_train)\n",
    "    block_length = int(N // data_scale)\n",
    "    start, end = block_length * index, block_length * index + block_length\n",
    "    return {'X_tr' : X_train[start : end], 'X_test' : X_test, 'y_tr': y_train[start : end], 'y_test' : y_test, 'z_tr': z_train[start: end], 'z_test' : z_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd2f53b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data, seed, method=\"logistic\"):\n",
    "    if method == 'logistic':\n",
    "        base_clf = LogisticRegression\n",
    "    elif method == 'gbm':\n",
    "        base_clf = ensemble.GradientBoostingClassifier\n",
    "    elif method == 'svm':\n",
    "        base_clf = svm.SVC\n",
    "    elif method == 'nn':\n",
    "        base_clf = MLPClassifier\n",
    "    elif method == \"tree\":\n",
    "        base_clf = DecisionTreeClassifier\n",
    "    \n",
    "    base_clf = make_pipeline(StandardScaler(), base_clf(random_state=seed))    \n",
    "    model = CalibratedClassifierCV(base_clf)\n",
    "    model.fit(data['X_tr'], data['y_tr'])\n",
    "        \n",
    "    scores = model.predict_proba(data['X_test'])\n",
    "    scores = [i[1] for i in scores]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07773601",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Homogenization:\n",
    "    def __init__(self, random_distance, num_models, data_scale, data_seed, model_type=None, application_type=None, model_seed=None, partition_seed=None, size=N_TEST):\n",
    "        self.random_distance = random_distance\n",
    "        self.num_models = num_models\n",
    "        self.data_scale = data_scale\n",
    "        self.data_seed = data_seed\n",
    "        self.model_seed = model_seed\n",
    "        self.partition_seed = partition_seed\n",
    "        self.model_type = model_type\n",
    "        self.application_type = application_type\n",
    "        \n",
    "        self.accuracy = []\n",
    "        self.acceptance = []\n",
    "        \n",
    "        self.systemic_success = (np.ones(size)==1)\n",
    "        self.systemic_failure = (np.ones(size)==1)\n",
    "        \n",
    "        self.failure_rate = 1\n",
    "        \n",
    "        self.fairness_spd = []\n",
    "        self.fairness_eop = []\n",
    "\n",
    "    def get_predictions(self, risk_scores):\n",
    "        pred = []\n",
    "        for r in risk_scores:\n",
    "            if (r > 0.5-self.random_distance) and (r < 0.5+self.random_distance):\n",
    "                pred.append(np.random.binomial(1, r))\n",
    "            elif (r >= 0.5):\n",
    "                pred.append(1)\n",
    "            else:\n",
    "                pred.append(0)\n",
    "        return np.array(pred)\n",
    "\n",
    "    def get_fairness_metrics(self, partition, pred):\n",
    "        df = pd.DataFrame(partition[\"z_test\"])\n",
    "        df[\"y_true\"] = partition[\"y_test\"]\n",
    "        df[\"y_pred\"] = pred\n",
    "        \n",
    "        m = df[df[0]==1]\n",
    "        f = df[df[0]==0]\n",
    "        \n",
    "        spd = (m[\"y_pred\"].sum()/len(m)) - (f[\"y_pred\"].sum()/len(f))\n",
    "        \n",
    "        df = df[df[\"y_true\"]==1]\n",
    "        m = df[df[0]==1]\n",
    "        f = df[df[0]==0]\n",
    "\n",
    "        eod = (m[\"y_pred\"].sum()/len(m)) - (f[\"y_pred\"].sum()/len(f))\n",
    "    \n",
    "        return spd, eod\n",
    "    \n",
    "    def update_metrics(self, partition, scores, method=\"lockout\"):\n",
    "        pred = self.get_predictions(scores)\n",
    "        spd, eop = self.get_fairness_metrics(partition, pred)\n",
    "        \n",
    "        self.accuracy.append(np.sum(pred==partition[\"y_test\"])/len(pred))\n",
    "        self.acceptance.append(np.sum(pred)/len(pred))\n",
    "        \n",
    "        self.fairness_spd.append(spd)\n",
    "        self.fairness_eop.append(eop)\n",
    "        \n",
    "        if method==\"lockout\":\n",
    "            self.failure_rate *= np.sum(pred==0)/len(pred)\n",
    "            self.systemic_success *= (pred==1)\n",
    "            self.systemic_failure *= (pred==0)\n",
    "        elif method==\"inaccurate\":\n",
    "            self.failure_rate *= np.sum(pred!=partition[\"y_test\"])/len(pred)\n",
    "            self.systemic_success *= (pred==partition[\"y_test\"])\n",
    "            self.systemic_failure *= (pred!=partition[\"y_test\"])\n",
    "        \n",
    "        \n",
    "    def final_metrics(self):\n",
    "        r = {}\n",
    "        r[\"random_distance\"] = self.random_distance\n",
    "        r[\"num_models\"] = self.num_models\n",
    "        r[\"data_scale\"] = self.data_scale\n",
    "        r[\"data_seed\"] = self.data_seed\n",
    "        r[\"model_seed\"] = self.model_seed\n",
    "        r[\"partition_seed\"] = self.partition_seed\n",
    "        r[\"model_type\"] = self.model_type\n",
    "        r[\"application_type\"] = self.application_type\n",
    "\n",
    "        r[\"accuracy\"] = np.mean(self.accuracy)\n",
    "        r[\"acceptance\"] = np.mean(self.acceptance)\n",
    "        r[\"fairness_spd\"] = np.mean(self.fairness_spd)\n",
    "        r[\"fairness_eop\"] = np.mean(self.fairness_eop)\n",
    "        \n",
    "        r[\"systemic_success\"] = np.sum(self.systemic_success)/len(self.systemic_success)\n",
    "        r[\"systemic_failure\"] = np.sum(self.systemic_failure)/len(self.systemic_failure)\n",
    "        r[\"multiplicity\"] = 1-r[\"systemic_success\"]-r[\"systemic_failure\"]\n",
    "        \n",
    "        r[\"failure_rate\"] = self.failure_rate\n",
    "        r[\"homogenization_expected_failure\"] = r[\"systemic_failure\"]/self.failure_rate\n",
    "        r[\"homogenization_avg_failure\"] = r[\"systemic_failure\"]/(1-r[\"acceptance\"])\n",
    "        \n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ecdf4e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelGroup: \n",
    "    def __init__(self, thresholds, method, num_models, data_scale, data_seed, model_type=None, application_type=None, model_seed=None, partition_seed=None, size=N_TEST):\n",
    "        self.models = []\n",
    "        self.method = method\n",
    "        for t in thresholds:\n",
    "            model = Homogenization(t, num_models, data_scale, data_seed, model_type, application_type, model_seed, partition_seed, size)\n",
    "            self.models.append(model)\n",
    "    \n",
    "    def update_metrics(self, partition, risk_scores):\n",
    "        for m in self.models:\n",
    "            m.update_metrics(partition, risk_scores, self.method)\n",
    "    \n",
    "    def final_metrics(self):\n",
    "        results = []\n",
    "        for m in self.models:\n",
    "            results.append(m.final_metrics())\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "978c465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_baseline(num_models=2, data_scale=1, method=\"lockout\"):\n",
    "    data_seeds = list(range(10))\n",
    "    partition_seed = 0\n",
    "    model_seed = 0\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for model_type in tqdm([\"logistic\", \"gbm\", \"nn\", \"svm\", \"tree\"], leave=False, desc=\"model\"):\n",
    "        for application in [\"is_good_loan\", \"is_high_credit\"]:\n",
    "            for data_seed in data_seeds:\n",
    "                data = format_data(german_credit, application, data_seed)\n",
    "                partition = fixed_partition(data, partition_seed, data_scale)\n",
    "                risk_scores = train_model(partition, model_seed, model_type)\n",
    "\n",
    "                models = ModelGroup([0, 0.1, 0.2, 0.3, 0.4, 0.5], method, num_models, data_scale, data_seed, model_type, None, None, None)\n",
    "                for k in range(num_models):\n",
    "                    models.update_metrics(partition, risk_scores)\n",
    "\n",
    "                results += models.final_metrics()\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d4f2cb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\n",
      "model:   0%|                                              | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "model:  20%|███████▌                              | 1/5 [00:00<00:01,  3.00it/s]\u001b[A\n",
      "model:  40%|███████████████▏                      | 2/5 [00:04<00:07,  2.51s/it]\u001b[A\n",
      "model:  60%|██████████████████████▊               | 3/5 [00:18<00:15,  7.85s/it]\u001b[A\n",
      "model:  80%|██████████████████████████████▍       | 4/5 [00:19<00:05,  5.04s/it]\u001b[A\n",
      "model: 100%|██████████████████████████████████████| 5/5 [00:19<00:00,  3.33s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:19<00:00, 19.61s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "# Homogenization As Number of Models Grows\n",
    "\n",
    "results = []\n",
    "for k in tqdm(range(1, 11)):\n",
    "    exp = experiment_baseline(k, 2, \"lockout\")\n",
    "    results.append(exp)\n",
    "results_df = pd.concat(results)\n",
    "\n",
    "results_df.to_csv(\"german_baseline_lockout.csv\", index=False)\n",
    "\n",
    "results = []\n",
    "for k in tqdm(range(1, 11)):\n",
    "    exp = experiment_baseline(k, 2, \"inaccurate\")\n",
    "    results.append(exp)\n",
    "results_df = pd.concat(results)\n",
    "\n",
    "results_df.to_csv(\"german_baseline_inaccurate.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be9a92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homogenization As Data Scale Grows\n",
    "\n",
    "results = []\n",
    "for data_scale in tqdm([20, 16, 10, 9, 8, 7, 6, 5, 4, 3, 2]):\n",
    "    exp = experiment_baseline(2, data_scale, \"lockout\")\n",
    "    results.append(exp)\n",
    "results_df = pd.concat(results)\n",
    "\n",
    "results_df.to_csv(\"german_baseline_lockout2.csv\", index=False)\n",
    "\n",
    "results = []\n",
    "for data_scale in tqdm([20, 16, 10, 9, 8, 7, 6, 5, 4, 3, 2]):\n",
    "    exp = experiment_baseline(2, data_scale, \"inaccurate\")\n",
    "    results.append(exp)\n",
    "results_df = pd.concat(results)\n",
    "\n",
    "results_df.to_csv(\"german_baseline_inaccurate2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d897dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
