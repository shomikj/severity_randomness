{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be97283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm, ensemble\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import itertools\n",
    "from folktables import ACSDataSource, ACSEmployment, ACSIncomePovertyRatio, ACSHealthInsurance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bfa6b2",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baad157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRAIN = 2588885\n",
    "N_TEST = 647222\n",
    "TASK_TYPES = [\"employment\", \"income-poverty\", \"health-insurance\"]\n",
    "\n",
    "root_dir = 'data'\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person', root_dir = root_dir)\n",
    "acs_data = data_source.get_data(download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2992795b",
   "metadata": {},
   "source": [
    "# Experiment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c45aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TYPES = [\"logistic\", \"gbm\", \"nn\", \"svm\", \"tree\"]\n",
    "RANDOM_THRESHOLDS = [0, 0.1, 0.2, 0.3, 0.4, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099ca5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(acs_data, application_name, seed):\n",
    "    name2application = {'employment' : ACSEmployment, 'income-poverty' : ACSIncomePovertyRatio, 'health-insurance' : ACSHealthInsurance}\n",
    "    application = name2application[application_name]\n",
    "    application_matrices = application.df_to_numpy(acs_data)\n",
    "\n",
    "    df = pd.DataFrame(application_matrices[0])\n",
    "    df[\"y\"] = application_matrices[1]\n",
    "    df[\"race\"] = application_matrices[2]\n",
    "    df[\"race\"] = (df[\"race\"]==1).astype(int)\n",
    "    \n",
    "    df_train, df_test = sklearn.model_selection.train_test_split(df, test_size=0.2, random_state=seed)\n",
    "\n",
    "    X_train, X_test = df_train.drop(columns=[\"y\", \"race\"]).to_numpy(), df_test.drop(columns=[\"y\", \"race\"]).to_numpy()\n",
    "    y_train, y_test = df_train[\"y\"].to_numpy(), df_test[\"y\"].to_numpy()\n",
    "    z_train, z_test = df_train[\"race\"].to_numpy(), df_test[\"race\"].to_numpy()\n",
    "    \n",
    "    return {'X_tr' : X_train, 'X_test' : X_test, 'y_tr': y_train, 'y_test' : y_test, 'z_tr': z_train, 'z_test': z_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c707679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_partition(data, seed, data_scale):\n",
    "    rng = random.Random(seed)\n",
    "    index = rng.randint(0, int(data_scale) - 1)\n",
    "\n",
    "    X_train, y_train, z_train = data['X_tr'], data['y_tr'], data['z_tr']\n",
    "    X_test, y_test, z_test = data['X_test'], data['y_test'], data['z_test']\n",
    "    y_train = np.expand_dims(y_train, axis = 1)\n",
    "    z_train = np.expand_dims(z_train, axis = 1)\n",
    "    data = np.concatenate((X_train, y_train, z_train), axis = 1)\n",
    "    np.random.RandomState(seed=seed).shuffle(data)\n",
    "    X_train, y_train, z_train = data[:, : -2], data[:, -2], data[:, -1]\n",
    "\n",
    "    N = len(y_train)\n",
    "    block_length = int(N // data_scale)\n",
    "    start, end = block_length * index, block_length * index + block_length\n",
    "    return {'X_tr' : X_train[start : end], 'X_test' : X_test, 'y_tr': y_train[start : end], 'y_test' : y_test, 'z_tr': z_train[start: end], 'z_test' : z_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2f53b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data, seed, method=\"logistic\"):\n",
    "    if method == 'logistic':\n",
    "        base_clf = LogisticRegression\n",
    "    elif method == 'gbm':\n",
    "        base_clf = ensemble.GradientBoostingClassifier\n",
    "    elif method == 'svm':\n",
    "        base_clf = svm.SVC\n",
    "    elif method == 'nn':\n",
    "        base_clf = MLPClassifier\n",
    "    elif method == \"tree\":\n",
    "        base_clf = DecisionTreeClassifier\n",
    "    \n",
    "    base_clf = make_pipeline(StandardScaler(), base_clf(random_state=seed))    \n",
    "    model = CalibratedClassifierCV(base_clf)\n",
    "    model.fit(data['X_tr'], data['y_tr'])\n",
    "        \n",
    "    scores = model.predict_proba(data['X_test'])\n",
    "    scores = [i[1] for i in scores]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07773601",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Homogenization:\n",
    "    def __init__(self, random_distance, num_models, data_scale, data_seed, model_type=None, application_type=None, model_seed=None, partition_seed=None, size=N_TEST):\n",
    "        self.random_distance = random_distance\n",
    "        self.num_models = num_models\n",
    "        self.data_scale = data_scale\n",
    "        self.data_seed = data_seed\n",
    "        self.model_seed = model_seed\n",
    "        self.partition_seed = partition_seed\n",
    "        self.model_type = model_type\n",
    "        self.application_type = application_type\n",
    "        \n",
    "        self.accuracy = []\n",
    "        self.acceptance = []\n",
    "        \n",
    "        self.systemic_success = (np.ones(size)==1)\n",
    "        self.systemic_failure = (np.ones(size)==1)\n",
    "        \n",
    "        self.failure_rate = 1\n",
    "        \n",
    "        self.fairness_spd = []\n",
    "        self.fairness_eop = []\n",
    "\n",
    "    def get_predictions(self, risk_scores):\n",
    "        pred = []\n",
    "        for r in risk_scores:\n",
    "            if (r > 0.5-self.random_distance) and (r < 0.5+self.random_distance):\n",
    "                pred.append(np.random.binomial(1, r))\n",
    "            elif (r >= 0.5):\n",
    "                pred.append(1)\n",
    "            else:\n",
    "                pred.append(0)\n",
    "        return np.array(pred)\n",
    "\n",
    "    def get_fairness_metrics(self, partition, pred):\n",
    "        df = pd.DataFrame(partition[\"z_test\"])\n",
    "        df[\"y_true\"] = partition[\"y_test\"]\n",
    "        df[\"y_pred\"] = pred\n",
    "        \n",
    "        m = df[df[0]==1]\n",
    "        f = df[df[0]==0]\n",
    "        \n",
    "        spd = (m[\"y_pred\"].sum()/len(m)) - (f[\"y_pred\"].sum()/len(f))\n",
    "        \n",
    "        df = df[df[\"y_true\"]==1]\n",
    "        m = df[df[0]==1]\n",
    "        f = df[df[0]==0]\n",
    "\n",
    "        eod = (m[\"y_pred\"].sum()/len(m)) - (f[\"y_pred\"].sum()/len(f))\n",
    "    \n",
    "        return spd, eod\n",
    "    \n",
    "    def update_metrics(self, partition, scores, method=\"lockout\"):\n",
    "        pred = self.get_predictions(scores)\n",
    "        spd, eop = self.get_fairness_metrics(partition, pred)\n",
    "        \n",
    "        self.accuracy.append(np.sum(pred==partition[\"y_test\"])/len(pred))\n",
    "        self.acceptance.append(np.sum(pred)/len(pred))\n",
    "        \n",
    "        self.fairness_spd.append(spd)\n",
    "        self.fairness_eop.append(eop)\n",
    "        \n",
    "        if method==\"lockout\":\n",
    "            self.failure_rate *= np.sum(pred==0)/len(pred)\n",
    "            self.systemic_success *= (pred==1)\n",
    "            self.systemic_failure *= (pred==0)\n",
    "        elif method==\"inaccurate\":\n",
    "            self.failure_rate *= np.sum(pred!=partition[\"y_test\"])/len(pred)\n",
    "            self.systemic_success *= (pred==partition[\"y_test\"])\n",
    "            self.systemic_failure *= (pred!=partition[\"y_test\"])\n",
    "        \n",
    "    def final_metrics(self):\n",
    "        r = {}\n",
    "        r[\"random_distance\"] = self.random_distance\n",
    "        r[\"num_models\"] = self.num_models\n",
    "        r[\"data_scale\"] = self.data_scale\n",
    "        r[\"data_seed\"] = self.data_seed\n",
    "        r[\"model_seed\"] = self.model_seed\n",
    "        r[\"partition_seed\"] = self.partition_seed\n",
    "        r[\"model_type\"] = self.model_type\n",
    "        r[\"application_type\"] = self.application_type\n",
    "\n",
    "        r[\"accuracy\"] = np.mean(self.accuracy)\n",
    "        r[\"acceptance\"] = np.mean(self.acceptance)\n",
    "        r[\"fairness_spd\"] = np.mean(self.fairness_spd)\n",
    "        r[\"fairness_eop\"] = np.mean(self.fairness_eop)\n",
    "        \n",
    "        r[\"systemic_success\"] = np.sum(self.systemic_success)/len(self.systemic_success)\n",
    "        r[\"systemic_failure\"] = np.sum(self.systemic_failure)/len(self.systemic_failure)\n",
    "        r[\"multiplicity\"] = 1-r[\"systemic_success\"]-r[\"systemic_failure\"]\n",
    "        \n",
    "        r[\"failure_rate\"] = self.failure_rate\n",
    "        r[\"homogenization_expected_failure\"] = r[\"systemic_failure\"]/self.failure_rate\n",
    "        r[\"homogenization_avg_failure\"] = r[\"systemic_failure\"]/(1-r[\"acceptance\"])\n",
    "        \n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdf4e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelGroup: \n",
    "    def __init__(self, thresholds, method, num_models, data_scale, data_seed, model_type=None, application_type=None, model_seed=None, partition_seed=None, size=N_TEST):\n",
    "        self.models = []\n",
    "        self.method = method\n",
    "        for t in thresholds:\n",
    "            model = Homogenization(t, num_models, data_scale, data_seed, model_type, application_type, model_seed, partition_seed, size)\n",
    "            self.models.append(model)\n",
    "        \n",
    "    def update_metrics(self, partition, risk_scores):\n",
    "        for m in self.models:\n",
    "            m.update_metrics(partition, risk_scores, self.method)\n",
    "    \n",
    "    def final_metrics(self):\n",
    "        results = []\n",
    "        for m in self.models:\n",
    "            results.append(m.final_metrics())\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962d8a20",
   "metadata": {},
   "source": [
    "# Experiment 1: Baseline (Same Model + Data + Prediction Task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978c465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_baseline(num_models=2, data_scale=10, method=\"lockout\"):\n",
    "    data_seeds = list(range(5))\n",
    "    partition_seed = 0\n",
    "    model_seed = 0\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for model_type in tqdm(MODEL_TYPES, leave=False, desc=\"model\"):\n",
    "        for application in TASK_TYPES:\n",
    "            for data_seed in data_seeds:\n",
    "                data = format_data(acs_data, application, data_seed)\n",
    "                partition = fixed_partition(data, partition_seed, data_scale)\n",
    "                risk_scores = train_model(partition, model_seed, model_type)\n",
    "\n",
    "                models = ModelGroup(RANDOM_THRESHOLDS, method, num_models, data_scale, data_seed, model_type, None, None, None)\n",
    "                for k in range(num_models):\n",
    "                    models.update_metrics(partition, risk_scores)\n",
    "\n",
    "                results += models.final_metrics()\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f2cb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homogenization As Number of Models Grows\n",
    "\n",
    "NUM_MODELS = range(1, 2)\n",
    "\n",
    "results = []\n",
    "for k in tqdm(NUM_MODELS):\n",
    "    exp = experiment_baseline(k, 10, \"lockout\")\n",
    "    results.append(exp)\n",
    "results_df = pd.concat(results)\n",
    "\n",
    "results_df.to_csv(\"baseline_models_lockout.csv\", index=False)\n",
    "\n",
    "results = []\n",
    "for k in tqdm(NUM_MODELS):\n",
    "    exp = experiment_baseline(k, 10, \"inaccurate\")\n",
    "    results.append(exp)\n",
    "results_df = pd.concat(results)\n",
    "\n",
    "results_df.to_csv(\"baseline_models_inaccurate.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be9a92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homogenization As Data Scale Grows\n",
    "\n",
    "NUM_DATA = [25000, 10000, 7500, 5000, 2500, 1000, 750, 500, 250, 100, 50, 10]\n",
    "\n",
    "results = []\n",
    "for data_scale in tqdm(NUM_DATA):\n",
    "    exp = experiment_baseline(2, data_scale, \"lockout\")\n",
    "    results.append(exp)\n",
    "results_df = pd.concat(results)\n",
    "\n",
    "results_df.to_csv(\"baseline_data_lockout.csv\", index=False)\n",
    "\n",
    "results = []\n",
    "for data_scale in tqdm(NUM_DATA):\n",
    "    exp = experiment_baseline(2, data_scale, \"inaccurate\")\n",
    "    results.append(exp)\n",
    "results_df = pd.concat(results)\n",
    "\n",
    "results_df.to_csv(\"baseline_data_inaccurate.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b4a84d",
   "metadata": {},
   "source": [
    "# Experiment 2: Different Prediction Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445e9940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_tasks(num_models=2, data_scale=10, method=\"lockout\"):\n",
    "    data_seeds = list(range(5))\n",
    "    partition_seed = 0\n",
    "    model_seed = 0\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for model_type in tqdm(MODEL_TYPES, leave=False, desc=\"model\"):\n",
    "        for data_seed in data_seeds:\n",
    "            models = ModelGroup(RANDOM_THRESHOLDS, method, num_models, data_scale, data_seed, model_type, None, None, None)\n",
    "            for application in TASK_TYPES:\n",
    "                data = format_data(acs_data, application, data_seed)\n",
    "                partition = fixed_partition(data, partition_seed, data_scale)\n",
    "                risk_scores = train_model(partition, model_seed, model_type)\n",
    "\n",
    "                models.update_metrics(partition, risk_scores)\n",
    "\n",
    "            results += models.final_metrics()\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83159f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homogenization As Number of Models Grows\n",
    "\n",
    "NUM_MODELS = [3]\n",
    "\n",
    "results = []\n",
    "for k in tqdm(NUM_MODELS):\n",
    "    exp = experiment_tasks(k, 10, \"lockout\")\n",
    "    results.append(exp)\n",
    "results_df = pd.concat(results)\n",
    "\n",
    "results_df.to_csv(\"tasks_models_lockout.csv\", index=False)\n",
    "\n",
    "results = []\n",
    "for k in tqdm(NUM_MODELS):\n",
    "    exp = experiment_tasks(k, 10, \"inaccurate\")\n",
    "    results.append(exp)\n",
    "results_df = pd.concat(results)\n",
    "\n",
    "results_df.to_csv(\"tasks_models_inaccurate.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d897dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homogenization As Data Scale Grows\n",
    "\n",
    "NUM_DATA = [25000, 10000, 7500, 5000, 2500, 1000, 750, 500, 250, 100, 50, 10]\n",
    "\n",
    "results = []\n",
    "for data_scale in tqdm(NUM_DATA):\n",
    "    exp = experiment_tasks(3, data_scale, \"lockout\")\n",
    "    results.append(exp)\n",
    "results_df = pd.concat(results)\n",
    "\n",
    "results_df.to_csv(\"tasks_data_lockout.csv\", index=False)\n",
    "\n",
    "results = []\n",
    "for data_scale in tqdm(NUM_DATA):\n",
    "    exp = experiment_tasks(3, data_scale, \"inaccurate\")\n",
    "    results.append(exp)\n",
    "results_df = pd.concat(results)\n",
    "\n",
    "results_df.to_csv(\"tasks_data_inaccurate.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c1e8b3",
   "metadata": {},
   "source": [
    "# Experiment 3: Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4f5e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_models(num_models=2, data_scale=10, method=\"lockout\"):\n",
    "    data_seeds = list(range(5))\n",
    "    partition_seed = 0\n",
    "    model_seed = 0\n",
    "    \n",
    "    model_groups = list(itertools.combinations(MODEL_TYPES, num_models))\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for application in TASK_TYPES:\n",
    "        for data_seed in data_seeds:\n",
    "            data = format_data(acs_data, application, data_seed)\n",
    "            partition = fixed_partition(data, partition_seed, data_scale)\n",
    "            \n",
    "            for model_group in model_groups:\n",
    "                \n",
    "                models = ModelGroup(RANDOM_THRESHOLDS, method, num_models, data_scale, data_seed, model_group, None, None, None)\n",
    "\n",
    "                for model_type in model_group:\n",
    "                    risk_scores = train_model(partition, model_seed, model_type)\n",
    "                    models.update_metrics(partition, risk_scores)\n",
    "\n",
    "                results += models.final_metrics()\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba529176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homogenization As Number of Models Grows\n",
    "\n",
    "NUM_MODELS = [1, 2, 3, 4, 5]\n",
    "\n",
    "results = []\n",
    "for k in tqdm(NUM_MODELS):\n",
    "    exp = experiment_models(k, 10, \"lockout\")\n",
    "    results.append(exp)\n",
    "results_df = pd.concat(results)\n",
    "\n",
    "results_df.to_csv(\"models_models_lockout.csv\", index=False)\n",
    "\n",
    "results = []\n",
    "for k in tqdm(NUM_MODELS):\n",
    "    exp = experiment_models(k, 10, \"inaccurate\")\n",
    "    results.append(exp)\n",
    "results_df = pd.concat(results)\n",
    "\n",
    "results_df.to_csv(\"models_models_inaccurate.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baf7791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homogenization As Data Scale Grows\n",
    "\n",
    "NUM_DATA = [25000, 10000, 7500, 5000, 2500, 1000, 750, 500, 250, 100, 50, 10]\n",
    "\n",
    "results = []\n",
    "for data_scale in tqdm(NUM_DATA):\n",
    "    exp = experiment_models(2, data_scale, \"lockout\")\n",
    "    results.append(exp)\n",
    "results_df = pd.concat(results)\n",
    "\n",
    "results_df.to_csv(\"models_data_lockout.csv\", index=False)\n",
    "\n",
    "results = []\n",
    "for data_scale in tqdm(NUM_DATA):\n",
    "    exp = experiment_models(2, data_scale, \"inaccurate\")\n",
    "    results.append(exp)\n",
    "results_df = pd.concat(results)\n",
    "\n",
    "results_df.to_csv(\"models_data_inaccurate.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4775041d",
   "metadata": {},
   "source": [
    "# Experiment 4: Different Data Partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53c9434",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
